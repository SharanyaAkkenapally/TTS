{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nXSnpiM8geY5","executionInfo":{"status":"ok","timestamp":1714086809985,"user_tz":240,"elapsed":72446,"user":{"displayName":"Sharanya Akkenapally","userId":"18275682436347199328"}}},"outputs":[],"source":["%%capture\n","pip install speechbrain"]},{"cell_type":"code","source":["import re\n","import logging\n","import torch\n","import torchaudio\n","import random\n","import speechbrain as sb"],"metadata":{"id":"L0_vTTl1qwiI","executionInfo":{"status":"ok","timestamp":1714086821219,"user_tz":240,"elapsed":11238,"user":{"displayName":"Sharanya Akkenapally","userId":"18275682436347199328"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1714087426970,"user":{"displayName":"Sharanya Akkenapally","userId":"18275682436347199328"},"user_tz":240},"id":"QGHlui0dpNVd","outputId":"b50e1ce9-8982-46bc-8b21-779dcc3b9b5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting hyperparams.yaml\n"]}],"source":["%%file hyperparams.yaml\n","\n","\n","# Define the vocabulary size\n","vocab_size: 70\n","blank_index: 0  # For padding\n","\n","\n","# Training hyperparameters\n","number_of_epochs: 10\n","batch_size: 8\n","learning_rate: 0.0001\n","\n","weight_decay: 0.000001\n","betas: [0.9, 0.98]\n","\n","\n","lexicon:\n","  - AA\n","  - AE\n","  - AH\n","  - AO\n","  - AW\n","  - AY\n","  - B\n","  - CH\n","  - D\n","  - DH\n","  - EH\n","  - ER\n","  - EY\n","  - F\n","  - G\n","  - HH\n","  - IH\n","  - IY\n","  - JH\n","  - K\n","  - L\n","  - M\n","  - N\n","  - NG\n","  - OW\n","  - OY\n","  - P\n","  - R\n","  - S\n","  - SH\n","  - T\n","  - TH\n","  - UH\n","  - UW\n","  - V\n","  - W\n","  - Y\n","  - Z\n","  - ZH\n","  - ' '\n","\n","\n","# Model hyperparameters\n","d_model: 512\n","nhead: 8\n","num_encoder_layers: 6\n","num_decoder_layers: 6\n","dim_feedforward: 2048\n","dropout: 0.1\n","\n","sample_rate: 22050\n","hop_length: 256\n","win_length: null\n","n_mel_channels: 80\n","n_fft: 1024\n","mel_fmin: 0.0\n","mel_fmax: 8000.0\n","power: 1\n","norm: \"slaney\"\n","mel_scale: \"slaney\"\n","dynamic_range_compression: True\n","mel_normalized: False\n","min_max_energy_norm: True\n","min_f0: 65  #(torchaudio pyin values)\n","max_f0: 2093 #(torchaudio pyin values)\n","\n","\n","# Epoch counter\n","epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n","    limit: !ref <number_of_epochs>\n","\n","# Transformer model\n","Seq2SeqTransformer: !new:torch.nn.Transformer\n","    d_model: !ref <d_model>\n","    nhead: !ref <nhead>\n","    num_encoder_layers: !ref <num_encoder_layers>\n","    num_decoder_layers: !ref <num_decoder_layers>\n","    dim_feedforward: !ref <dim_feedforward>\n","    dropout: !ref <dropout>\n","    batch_first: True\n","\n","# Embeddings\n","encoder_emb: !new:torch.nn.Embedding\n","    num_embeddings: !ref <vocab_size>\n","    embedding_dim: !ref <d_model>\n","    padding_idx: !ref <blank_index>\n","\n","decoder_emb: !new:torch.nn.Embedding\n","    num_embeddings: !ref <vocab_size>\n","    embedding_dim: !ref <d_model>\n","    padding_idx: !ref <blank_index>\n","\n","# Positional embeddings and custom prenets\n","pos_emb: !new:custom_model.ScaledPositionalEncoding\n","    d_model: !ref <d_model>\n","    max_len: 5000\n","\n","encoder_prenet: !new:custom_model.EncoderPrenet\n","    embedding_dim: !ref <d_model>\n","    num_channels: 512\n","    kernel_size: 5\n","    dropout_rate: 0.5\n","\n","decoder_prenet: !new:custom_model.DecoderPrenet\n","    input_dim: 80  # Number of mel channels\n","    hidden_dim: 256\n","    output_dim: !ref <d_model>\n","    final_dim: !ref <d_model>\n","    dropout_rate: 0.5\n","\n","# Tacotron2 specific modules from SpeechBrain\n","postnet: !new:speechbrain.lobes.models.Tacotron2.Postnet\n","\n","mel_spectogram: !name:speechbrain.lobes.models.FastSpeech2.mel_spectogram\n","    sample_rate: !ref <sample_rate>\n","    hop_length: !ref <hop_length>\n","    win_length: !ref <win_length>\n","    n_fft: !ref <n_fft>\n","    n_mels: !ref <n_mel_channels>\n","    f_min: !ref <mel_fmin>\n","    f_max: !ref <mel_fmax>\n","    power: !ref <power>\n","    normalized: !ref <mel_normalized>\n","    min_max_energy_norm: !ref <min_max_energy_norm>\n","    norm: !ref <norm>\n","    mel_scale: !ref <mel_scale>\n","    compression: !ref <dynamic_range_compression>\n","\n","\n","mel_linear: !new:speechbrain.nnet.linear.Linear\n","    input_size: !ref <d_model>\n","    n_neurons: 80  # Number of mel channels\n","\n","stop_linear: !new:speechbrain.nnet.linear.Linear\n","    input_size: !ref <d_model>\n","    n_neurons: 1\n","\n","input_encoder: !new:speechbrain.dataio.encoder.TextEncoder\n","\n","# Masks\n","lookahead_mask: !name:speechbrain.lobes.models.transformer.Transformer.get_lookahead_mask\n","padding_mask: !name:speechbrain.lobes.models.transformer.Transformer.get_key_padding_mask\n","\n","\n","modules:\n","    Seq2SeqTransformer: !ref <Seq2SeqTransformer>\n","    encoder_emb: !ref <encoder_emb>\n","    decoder_emb: !ref <decoder_emb>\n","    pos_emb: !ref <pos_emb>\n","    encoder_prenet: !ref <encoder_prenet>\n","    decoder_prenet: !ref <decoder_prenet>\n","    postnet: !ref <postnet>\n","    mel_linear: !ref <mel_linear>\n","    stop_linear: !ref <stop_linear>\n","\n","model: !new:torch.nn.ModuleList.\n","    - [!ref <Seq2SeqTransformer>, !ref <encoder_emb>, !ref <decoder_emb>, !ref <pos_emb>, !ref <encoder_prenet>, !ref <decoder_prenet>, !ref <postnet>, !ref <mel_linear>, !ref <stop_linear>]\n","\n","\n","\n","pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer\n","    loadables:\n","        model: !ref <model>\n","        input_encoder: !ref <input_encoder>\n","\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"xL9ojZmiJ6FB","executionInfo":{"status":"ok","timestamp":1714087811732,"user_tz":240,"elapsed":7,"user":{"displayName":"Sharanya Akkenapally","userId":"18275682436347199328"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"418a5897-9cf0-4f5c-9eb4-df66e27b2908"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing TextToSpeech.py\n"]}],"source":["%%file TextToSpeech.py\n","from speechbrain.utils.fetching import fetch\n","from speechbrain.inference.interfaces import Pretrained\n","from speechbrain.inference.text import GraphemeToPhoneme\n","\n","\n","logger = logging.getLogger(__name__)\n","\n","\n","class TextToSpeech(Pretrained):\n","    \"\"\"\n","    A ready-to-use wrapper for Transformer TTS (text -> mel_spec).\n","    Arguments\n","    ---------\n","    hparams\n","        Hyperparameters (from HyperPyYAML)\"\"\"\n","\n","    HPARAMS_NEEDED = [\"model\", \"blank_index\", \"padding_mask\", \"lookahead_mask\", \"mel_spectogram\", \"input_encoder\"]\n","    MODULES_NEEDED = [\"modules\"]\n","\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.input_encoder = self.hparams.input_encoder\n","        self.input_encoder.update_from_iterable(self.hparams.lexicon,sequence_input=False)\n","        self.g2p = GraphemeToPhoneme.from_hparams(\"speechbrain/soundchoice-g2p\")\n","\n","\n","    def text_to_phoneme(self, text):\n","        \"\"\"\n","        Generates phoneme sequences for the given text using a Grapheme-to-Phoneme (G2P) model.\n","\n","        Args:\n","            text (str): The input text.\n","\n","        Returns:\n","            list: List of phoneme sequences for the words in the text.\n","        \"\"\"\n","        abbreviation_expansions = {\n","            \"Mr.\": \"Mister\",\n","            \"Mrs.\": \"Misess\",\n","            \"Dr.\": \"Doctor\",\n","            \"No.\": \"Number\",\n","            \"St.\": \"Saint\",\n","            \"Co.\": \"Company\",\n","            \"Jr.\": \"Junior\",\n","            \"Maj.\": \"Major\",\n","            \"Gen.\": \"General\",\n","            \"Drs.\": \"Doctors\",\n","            \"Rev.\": \"Reverend\",\n","            \"Lt.\": \"Lieutenant\",\n","            \"Hon.\": \"Honorable\",\n","            \"Sgt.\": \"Sergeant\",\n","            \"Capt.\": \"Captain\",\n","            \"Esq.\": \"Esquire\",\n","            \"Ltd.\": \"Limited\",\n","            \"Col.\": \"Colonel\",\n","            \"Ft.\": \"Fort\"\n","        }\n","\n","        for abbreviation, expansion in abbreviation_expansions.items():\n","            text = text.replace(abbreviation, expansion)\n","\n","        phonemes = self.g2p(text)\n","        phonemes = self.input_encoder.encode_sequence(phonemes)\n","        phoneme_seq = torch.LongTensor(phonemes)\n","\n","        return phoneme_seq, len(phoneme_seq)\n","\n","    def encode_batch(self, texts):\n","        \"\"\"Computes mel-spectrogram for a list of texts\n","\n","        Texts must be sorted in decreasing order on their lengths\n","\n","        Arguments\n","        ---------\n","        texts: List[str]\n","            texts to be encoded into spectrogram\n","\n","        Returns\n","        -------\n","        tensors of output spectrograms, output lengths and alignments\n","        \"\"\"\n","        with torch.no_grad():\n","          phonemes = [self.text_to_phoneme(text)[0] for text in texts]\n","          phoneme_padded, lengths = self.pad_sequences(phonemes)\n","          phonemes_emb = self.mods.encoder_emb(phoneme_padded)\n","          encoder_prenet_out = self.mods.encoder_prenet(phonemes_emb)\n","          pos_enc_output = self.mods.pos_emb(encoder_prenet_out)\n","          enc_emb = pos_enc_output + encoder_prenet_out\n","\n","          # Initialize decoder inputs for autoregressive generation\n","          decoder_input = torch.zeros(1, 1, 80, device=self.device)\n","          res = []\n","          stop_token_predictions_list=[]\n","          stop_condition = False\n","          itr=0\n","          max_itr=1000\n","          res.append(decoder_input)\n","\n","\n","          while not stop_condition and itr<max_itr:\n","\n","            decoder_prenet_out = self.mods.decoder_prenet(decoder_input)\n","            pos_dec_output = self.mods.pos_emb(decoder_prenet_out)\n","            dec_emb = decoder_prenet_out + pos_dec_output\n","\n","            src_mask = torch.zeros(enc_emb.size(1), enc_emb.size(1), device=self.device)\n","            src_key_padding_mask = self.hparams.padding_mask(enc_emb, pad_idx=self.hparams.blank_index)\n","\n","            decoder_outputs = self.mods.Seq2SeqTransformer(enc_emb, dec_emb, src_mask=src_mask,\n","                                                              src_key_padding_mask=src_key_padding_mask\n","                                                              )\n","            mel_pred = self.mods.mel_linear(decoder_outputs).transpose(1,2)\n","            postnet_out=self.mods.postnet(mel_pred)\n","            mel_predictions=mel_pred+postnet_out\n","\n","            stop_token_predictions= self.mods.stop_linear(decoder_outputs).squeeze(-1)\n","            stop_token_predictions_list.append(stop_token_predictions)\n","\n","            decoder_input=mel_predictions.transpose(1,2)\n","            res.append(decoder_input)\n","            itr=itr+1\n","\n","          final_res=torch.cat(res,dim=1)\n","          final_stop_tokens=torch.cat(stop_token_predictions_list,dim=1)\n","\n","          return final_res.transpose(1, 2)\n","\n","    def should_stop(self, stop_token_pred):\n","        # Implement your stopping condition here.\n","        # This could check for a predicted end-of-sequence token or a maximum length.\n","        # Convert logits to probabilities (assuming binary classification with sigmoid activation).\n","        stop_prob = torch.sigmoid(stop_token_pred).squeeze(-1)\n","        stop_decision = stop_prob > 0.5\n","        return stop_decision.any().item()\n","\n","    def pad_sequences(self, sequences):\n","      \"\"\"Pad sequences to the maximum length sequence in the batch.\n","\n","      Arguments\n","      ---------\n","      sequences: List[torch.Tensor]\n","          The sequences to pad\n","\n","      Returns\n","      -------\n","      Padded sequences and original lengths\n","      \"\"\"\n","      max_length = max([len(seq) for seq in sequences])\n","      seq_padd = torch.zeros(len(sequences), max_length, dtype=torch.long)\n","      length_list = []\n","      for i, seq in enumerate(sequences):\n","          length = len(seq)\n","          seq_padd[i, :length] = seq\n","          length_list.append(length)\n","      return seq_padd, torch.tensor(length_list)\n","\n","    def encode_text(self, text):\n","        \"\"\"Runs inference for a single text str\"\"\"\n","        return self.encode_batch(text)\n","\n","    def forward(self, texts):\n","        \"Encodes the input texts.\"\n","        return self.encode_batch(texts)\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oKAfO-3ooO0W","outputId":"17c86080-21d9-46e2-b6cb-8fd6ff7bed41","executionInfo":{"status":"ok","timestamp":1714087766445,"user_tz":240,"elapsed":62997,"user":{"displayName":"Sharanya Akkenapally","userId":"18275682436347199328"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n","  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n","/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched src_key_padding_mask and mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]}],"source":["from speechbrain.inference.vocoders import HIFIGAN\n","\n","texts = [\"This is a example for synthesis.\"]\n","\n","my_tts_model = TextToSpeech.from_hparams(source=\"/content/\")\n","hifi_gan = HIFIGAN.from_hparams(source=\"speechbrain/tts-hifigan-ljspeech\", savedir=\"tmpdir_vocoder\")\n","mel_output = my_tts_model.encode_text(texts)\n","\n","# Running Vocoder (spectrogram-to-waveform)\n","waveforms = hifi_gan.decode_batch(mel_output)\n","\n","# Save the waverform\n","torchaudio.save('example_TTS.wav',waveforms.squeeze(1), 22050)"]},{"cell_type":"code","source":[],"metadata":{"id":"evRHCBg2kNso"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1VYu4kXdgpv7f742QGquA1G4ipD2Kg0kT","timestamp":1713300105795}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}